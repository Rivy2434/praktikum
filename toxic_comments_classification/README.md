# Classification of toxic comments 
This project aimed to create a model which can distinguish toxic and non-toxic comments with a minimum F1 score of 0.75.
Labeled data contains text comment in text and target in toxic.
For feature engineering, TF-IDF was used. Following libraries were used: pandas, nltk, sklearn, matplotlib, lightgbm, torch, spacy
